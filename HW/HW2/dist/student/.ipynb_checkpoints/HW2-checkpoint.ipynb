{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c48a4a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb02226-621a-453c-bb8d-5e3c2dc6c093",
   "metadata": {},
   "source": [
    "Due Date: 25 Mar 2025 by 11:59 pm\n",
    "\n",
    "Rubric:\n",
    "\n",
    "| Question | Points |  \n",
    "| :--- | ----------- |\n",
    "| 1 |  5 |\n",
    "| 2 | 5 |\n",
    "| 3 | 5 | \n",
    "| 4 | 5 |\n",
    "| 5 | 5 |\n",
    "| 6 | 5 |\n",
    "| 7 | 5 |\n",
    "| 8 | 5 |\n",
    "| 9 | 5|\n",
    "| 10 | 5 |\n",
    "| 11 | 5 | \n",
    "| 12 | 5 |\n",
    "| 13 | 5 |\n",
    "| 14 | 5 |\n",
    "| 15 | 5 |\n",
    "| 16 | 5 |\n",
    "| 17 | 5 |\n",
    "|18 | 15 |\n",
    "|Total | 100 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c294eb-da7c-4c8b-b248-11aaf6908d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8b72e-c5a2-4089-9b95-c6c9af49c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b0c66-918c-4cc6-ac1f-c27b866bf976",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "    \n",
    "Submission: Please upload the notebook(.ipynb) file on D2L HW2 dropbox. \n",
    "\n",
    "1. The HW assignment is individual-based assignment. Do not copy or show your code to others, otherwise proper action will be taken as described in the syllabus. \n",
    "\n",
    "2. Just because your question passed the autograder test, doesn't mean necessarily that your answer is correct. So make sure you answer those questions carefully. The instructor has some hidden tests, and only when your question passes those tests successfully during grading, you will be given full points for the question. \n",
    "\n",
    "3. If you are stuck somewhere, feel free to reach out to me. I promise I won't judge you and I want you to succeed.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9155e1d5-c370-45f1-99b4-2be8ed3e17a5",
   "metadata": {},
   "source": [
    "Objectives: \n",
    "1. Data exploration\n",
    "2. Feature engineering\n",
    "3. Scikit learn package\n",
    "4. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc11c6f-2768-496e-9f05-20caf7ff1fba",
   "metadata": {},
   "source": [
    "# A. Understanding the data\n",
    "\n",
    "You are given Cook County Assessor's Office dataset. This dataset is collected by the office to determine the property taxes across many areas of Chicago. The dataset consists of over 200,000 records describing houses sold in the Cook County in recent years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de150b92-2d35-439b-9892-b62233e31a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cook_county_data.csv', index_col=\"Unnamed: 0\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1599e6-78b8-4542-b2cf-b6bee30147ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b4867-36f8-4eae-a353-c075dab9045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68775d4b-6e4e-4dc0-abb5-b9de129b674a",
   "metadata": {},
   "source": [
    "A more detailed description of each feature is described in `cookbook.txt`. You should go through it to familiarize yourself with the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b53410-6b17-4f60-874c-ea45da686e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Description'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc6ec67-6b02-490a-9187-af612c3d80db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=42) # randomly splitting the dataset into train and test\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18204ecf-d901-47ed-89dd-301d5f014bc3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1: \n",
    "\n",
    "After going through all the features given in `data/cookbook.txt` file. Name one feature which is not in the list, which may play an important role in determining the house price. Also, explain how this feature may affect positively or negatively the house price. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607f341",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2927f834-6ac9-42f7-aad5-d3a506c25613",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 2: \n",
    "\n",
    "Apart from the internal features of a house such as number of bedrooms, garage, wall material etc, name one feature (given in the cookbook.txt) that might influence the price of a house. Explain why? \n",
    "\n",
    "Hint: Think about how a house location may affect its' sale price. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669630d9",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77eba0-b758-4fd0-bec7-5f5e902a4128",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# B. Ethics in Modeling \n",
    "\n",
    "When examining your data, it is important to understand how the data has been collected to identify if the data has certain issues such as noise or **biasness**. \n",
    "\n",
    "Suppose you are told that `Site Desirability` is collected based on real estate agent's expertise and experience. For eg: a real estate agent gave high `Site Desriability` score to the houses which are near high-ranking schools compared to the houses with are far from the high-ranking schoools. Because high-ranking schools are often located in high-income neighborhoods as they are funded by the property taxes, houses in such neighborhood would receive high points. Whereas, the low-income neighborhoods will get low site desirability score, further devaluing the house price. Historically, we know that Asian and White (not hispanic) have higher incomes than Black or Hispanic or American Indian. Therefore, Site Desirability is indirectly related to the racial identification of a neighborhood, as a result, an agent may induce some biasness to the site desirability based on his/her experience. Such biasness will lead to a racially biased model. It is important to be vigilant towards such features and how they are collected. If you don't know how the data of a column was collected, you should be vigilant about using it in your model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a49416-f021-4515-87b1-4a4c8452b501",
   "metadata": {},
   "source": [
    "# C. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f841d843-6f16-4311-bbfd-e10bf89fc1de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3\n",
    "\n",
    "Consider the following histogram plot for the `Sale Price`. What is the problem with the visualization below? Will standardizing the data will fix the problem? Explain why or why not. \n",
    "\n",
    "Recall standardization means: (X - mean) / standard deviation\n",
    "\n",
    "Hint: Look into the minimum value, maximum value and scale of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50af33a-59f7-4b8a-ab8f-5ccd4f2bda26",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train['Sale Price'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bc520-73f7-4497-81ff-a2180944d01d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "xmin = train['Sale Price'].min()\n",
    "xmax = train['Sale Price'].max()\n",
    "plt.hist(train['Sale Price'], bins = np.arange(xmin, xmax, 100000), density = True)\n",
    "plt.xlabel('Sale Price (in 10 million dollars)')\n",
    "plt.ylabel('fraction of houses per 10 million dollars')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd7f2a3",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a973e6-ead3-4a32-a944-7371398d8c40",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 4\n",
    "Fix the above visualization by:\n",
    "\n",
    "1. Remove all records where house price is less than 500 dollars. \n",
    "2. To tackle exponential decay, convert your 'Sale Price' to `log` of Sale Price. (you may use `np.log`)\n",
    "\n",
    "Store the transformed sale price in a new column `log_sale_price`. \n",
    "\n",
    "Perform these actions to both train and test dataset. \n",
    "\n",
    "Make sure in future, when you train your model, your target `Sale Price` is the log of Sale Price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27962280-016d-4465-9f88-d6441a405022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train.query(...) \n",
    "train['log_sale_price'] = ...\n",
    "\n",
    "xmin = np.min(train['log_sale_price'])\n",
    "xmax = np.max(train['log_sale_price'])\n",
    "plt.hist(train['log_sale_price'], bins = 100, density = True)\n",
    "plt.xlabel('Sale Price (in 10 million dollars)')\n",
    "plt.ylabel('fraction of houses per 10 million dollars')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8dd61",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56531ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eea4d3-444b-451d-872f-398005f3e358",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train['log_sale_price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d16959-5ebf-4aec-b828-c19fd083e5b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 5\n",
    "\n",
    "By looking at the descriptive statistics above, atleast 25% of the houses are sold for less than 150,000. True or False. Give reasons. \n",
    "\n",
    "Hint: If $ y = ln(x)$ then, $x = e^y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a47ec",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76717964-fe95-4167-9e79-4930de3c891e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6:\n",
    "\n",
    "Use pearson correlation coefficient (r) to determine if log of `Building Square Feet` will be useful feature to predict log of `Sale Price'. State your conclusion. \n",
    "\n",
    "Note: if r > 0.5, then there is strong positive correlation, and r < 0.5 strong negative correlation. \n",
    "\n",
    "Hint: Do not forget to remove the rows with Sale Price less than 500 dollars before log transformation, as we did in Question 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f7e288",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14080456-40fc-432e-a6dc-a62a384b2ef2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# D. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c98874-85e2-477d-bf54-5a1264785656",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 7\n",
    "\n",
    "There is no total bedrooms features given in the dataset directly. However, if you see the `Description` column, you will find that the information is available in the text. \n",
    "\n",
    "Write a function extract_total_bedrooms which returns a 2D array of total rooms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96553b60-2bec-45cc-af89-a5ed45b16ae7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e54cb3-6881-4640-bb2b-72e0b4a2c95d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "first_row = train.iloc[0]\n",
    "first_row.loc['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bb1cd-9a20-4aac-b2a6-8b62384e5e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a regex which will extract the number of bedrooms from a description text. \n",
    "regex = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5435763-17f4-44f9-9b65-1698bff508b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_bedrooms(X):\n",
    "    \"\"\"\n",
    "    X: a pandas series containing Description column with N items, where N = len(X)\n",
    "    - returns a 2D integer numpy array of shape (N, 1) of total rooms \n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e660f-550a-4887-aea5-180ae79cae6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrooms = extract_bedrooms(train['Description'])\n",
    "bedrooms[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b930cb7a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4dd89b-e226-4dc7-8508-1d42f8e8d239",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 8\n",
    "Select the correct visualization plot from the following to explore any relationship between `bedrooms vs Sale Price`. \n",
    "\n",
    "1. [Bar plot](https://seaborn.pydata.org/generated/seaborn.barplot.html)\n",
    "2. [Grouped violin plots](https://seaborn.pydata.org/generated/seaborn.violinplot.html) \n",
    "3. [Jointplot](https://seaborn.pydata.org/generated/seaborn.jointplot.html)\n",
    "4. [lmplot](https://seaborn.pydata.org/generated/seaborn.lmplot.html)\n",
    "5. [swarmplot](https://seaborn.pydata.org/generated/seaborn.swarmplot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8347842",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c34948-f3b7-4abe-8be7-74a7656f3726",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 9\n",
    "Write python code to visualize the plot that you selected in Question8 to find the relationship. State the relationship that you deduced from the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ee57f-4d14-41f5-96eb-49d7b13e9b06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef6d16-0179-4a4b-8d17-af18013ad5a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 10\n",
    "\n",
    "Find how many different neighborhoods are there in the train dataset.  Store your result in the variable `num_neighborhoods`\n",
    "\n",
    "Hint: Check `Neighborhood Code` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857657c6-26bf-47d4-b3f9-fe4494d93c86",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "num_neighborhoods = len(np.unique(train['Neighborhood Code'])) # SOLUTION\n",
    "num_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffb2d7-6278-4762-8416-5b2d5c17b4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_neighborhoods < 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d0ad4-b878-477d-99dd-bc7352a33b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical(neighborhoods, data, with_filter=True):\n",
    "    if not with_filter:\n",
    "        neighborhoods = data\n",
    "    fig, axs = plt.subplots(nrows=2, figsize=(15, 5))\n",
    "\n",
    "    sns.boxplot(\n",
    "        x='Neighborhood Code',\n",
    "        y= 'log_sale_price',\n",
    "        data=neighborhoods.sort_values('Neighborhood Code'),\n",
    "        ax=axs[0],\n",
    "    )\n",
    "\n",
    "    sns.countplot(\n",
    "        x='Neighborhood Code',\n",
    "        data=neighborhoods.sort_values('Neighborhood Code'),\n",
    "        ax=axs[1],\n",
    "    )\n",
    "\n",
    "    # Draw median price\n",
    "    axs[0].axhline(\n",
    "        y=train['log_sale_price'].median(), \n",
    "        color='red',\n",
    "        linestyle='dotted'\n",
    "    )\n",
    "\n",
    "    # Label the bars with counts\n",
    "    for patch in axs[1].patches:\n",
    "        x = patch.get_bbox().get_points()[:, 0]\n",
    "        y = patch.get_bbox().get_points()[1, 1]\n",
    "        axs[1].annotate(f'{int(y)}', (x.mean(), y), ha='center', va='bottom')\n",
    "\n",
    "    # Format x-axes\n",
    "    #axs[1].set_ticklabels(axs[1].xaxis.get_majorticklabels(), rotation=90)\n",
    "    #axs[0].xaxis.set_visible(False)\n",
    "\n",
    "    # Narrow the gap between the plots\n",
    "    plt.subplots_adjust(hspace=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9766313e-44ee-49d0-bf61-46c6ee0fefe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical(train, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc13647-4a41-4be8-a859-921d737224aa",
   "metadata": {},
   "source": [
    "The plot above shows the Log Sale Price for all households in each neighborhood using the `plot_categorical` function. It is overplotting(very crowded) since it's considering all the neighborhoods and therefore, it's hard to make sense of it. Let's fix this problem in the next question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0a539-b34f-47e7-b4fc-bd75314f2549",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 11\n",
    "\n",
    "\n",
    "Create a dataframe that consists of all the households that are located in the top 20 crowded neighborhoods. Store your answer in the variable `top20_crowded_neighborhoods`. \n",
    "\n",
    "A neighborhood is crowded based on the number of households that exists in the neighborhood. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f39476-444b-4c66-897d-97f4baa9546e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top20_busy_neighborhoods = ...\n",
    "top20_busy_neighborhoods = ...\n",
    "top20_busy_neighborhoods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0cbd89-86a0-4761-9857-ea5bbcb14302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_categorical(top20_busy_neighborhoods, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75e004-6284-4749-ae8a-0c2553c66e9f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 12\n",
    "\n",
    "What can you deduce about the relationship between neighborhoods and log of sale price? Do you think you should use this feature into your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4a206",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2403d2-381e-4fc3-8150-a0e04ece3abe",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# E. HW3 : Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650da965-8212-4ee6-b072-18f308f817ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08477dbb-5761-44f0-8312-b1a1a8bc614e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 13\n",
    "\n",
    "Create your first model (model1) which uses only one features: the number of bedrooms in the household \n",
    "\n",
    "$$Log Sale Price = \\theta_0 + \\theta_1 (Bedrooms)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82a63a-51ef-4aab-ac68-b11817a2841c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the columnAdder should create a bedroom feature to the dataset. \n",
    "columnAdder = ColumnTransformer([\n",
    "                                     ...\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e36a977-c841-4dcf-9f37-f5aafed93275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = Pipeline([\n",
    "                        ...\n",
    "                        ('model1', LinearRegression()) \n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efa5a0-b6f2-4dac-8855-c676d8614f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1.fit(train, train['log_sale_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c3bc7-9371-4cc4-afcc-6ca4a7b0f91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1.predict(test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b099c-030a-46d0-a4d0-a33b3b0739c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 14\n",
    "\n",
    "Create your second model (model2) which uses only two features: the number of bedrooms in the household and Log Building Square Feet\n",
    "\n",
    "$$Log Sale Price = \\theta_0 + \\theta_1 (Bedrooms) + \\theta_2(Log Building Square Feet)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd8b4f-8d07-410f-9c58-8c31807f2876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write a function which takes a feature X and returns a 2D log transformation of the feature\n",
    "def cal_log(X):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a10dd-dfbb-4999-b8d0-125d4828c2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columnAdder = ColumnTransformer([\n",
    "                                     ...\n",
    "                                     ...\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219be79-20ec-4a1a-b0ea-aa82b39fdaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = Pipeline([\n",
    "                        ...\n",
    "                        ('model2', LinearRegression()) \n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ae0db-4cd4-44c0-89e3-f248bb301e0a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.fit(train, train['log_sale_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4827411-5db8-40fa-bdb5-8462dca3c3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2.inte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29993e-b001-4c85-b7ff-40d894c33e8a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 15\n",
    "\n",
    "Divide your data into train(80%) and validation (20%) split, and answer the following question. \n",
    "\n",
    "Model2 is better than Model1 when compared based on rmse values on the validation set. True/False? \n",
    "\n",
    "You need to write code for to answer this. Show your solution process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf99821-7b6b-4647-9b17-67006467063d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42891559-065c-460a-986d-9742bad8e3fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f045e9a-9c15-461e-81f3-80464988db59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b5485-3ed4-477f-9478-2e1407a5f3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57d8e0-de4c-42e2-bc2e-abd0c45b309f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a0af0-360d-42cb-ad9c-37ccc8fcad3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef380609-3649-4e1b-bfd0-71702fc1696b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 16\n",
    "\n",
    "We are only utilizing two features at the moment. Perform further feature engineering (such as feature selection, feature transformation, handling missing values) on the remaining subset of columns to improve the model performance. Draw the residual plot for your final model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103e6f6-e5d1-49e1-b21e-a4bbf3c8f3d2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 17\n",
    "\n",
    "Add L2 regularization to your final model, and retrain your model. Report the final rmse value of your model on the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c172bf0-ad8f-4c8b-87f6-7c8cd320acdf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 18\n",
    "\n",
    "### Implementing your own custom Multiple Linear Regression Model \n",
    "\n",
    "In this part of the question, you will implement multiple linear regression model from scratch. In specific complete the following functions in the MLRModel class. \n",
    "\n",
    "Complete the methods below to train the MLR model using mini-batch gradient descent technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f51cc5-bb22-460e-ba19-84caa141c48b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import math\n",
    "\n",
    "class MLRModel(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lr = 0.01, batch_size = 32, n_epoch = 50):\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epoch = n_epoch\n",
    "        self.theta = None\n",
    "\n",
    "    def add_1(self, X):\n",
    "        \"\"\"\n",
    "        X: a numpy array of shape (m, n)\n",
    "        returns: a new array X, with shape (m, n+1) where the first column is a column vector of ones\n",
    "        \"\"\"\n",
    "        intercept = ...\n",
    "        ...\n",
    "\n",
    "    def hypothesis(self, X, theta):\n",
    "        \"\"\"\n",
    "        X: a numpy array of shape (m, n+1)\n",
    "        theta: a numpy array of shape (n+1, 1)\n",
    "\n",
    "        return: y_hat, a numpy array of shape (m, 1)\n",
    "        \"\"\"\n",
    "        #print(X.shape, theta.shape)\n",
    "        y_hat = ...\n",
    "        return y_hat\n",
    "\n",
    "    def gradient(self, X, y, theta):\n",
    "        \"\"\"\n",
    "        X: a numpy array of shape (m, n+1)\n",
    "        y: a numpy array of shape (m, 1)\n",
    "        theta: a numpy array of shape (n+1, 1)\n",
    "\n",
    "        returns: gradient vector (derivative of loss function wrt theta), a numpy array of shape (n+1, 1)\n",
    "        \"\"\"\n",
    "        y_hat = self.hypothesis(X, theta)\n",
    "        grad = ...\n",
    "        return grad\n",
    "\n",
    "    def cost(self, X, y, theta):\n",
    "        \"\"\"\n",
    "        X: a numpy array of shape (m, n+1)\n",
    "        y: a numpy array of shape (m, 1)\n",
    "        theta: a numpy array of shape (n+1, 1)\n",
    "\n",
    "        returns: rmse (a scalar) \n",
    "        \"\"\"\n",
    "        y_hat = self.hypothesis(X, theta)\n",
    "        cost = ...\n",
    "        return cost\n",
    "\n",
    "    def gradient_descent(self, X, y, theta):\n",
    "        \"\"\"\n",
    "        X: a numpy array of shape (m, n+1)\n",
    "        y: a numpy array of shape (m,1)\n",
    "        theta: a numpy array of shape (n+1, 1)\n",
    "\n",
    "        returns: updated theta according to the gradient descent algorithm\n",
    "        \"\"\"\n",
    "        theta = ...\n",
    "        return theta\n",
    "        \n",
    "\n",
    "    def fit(self, trainX = None, trainY = None, valX = None, valY = None):\n",
    "        m, n = trainX.shape\n",
    "        self.theta = np.zeros((n+1,1))\n",
    "\n",
    "        # add a column vector of 1's in X for the intercept/bias term\n",
    "        trainX = self.add_1(trainX)\n",
    "        valX = self.add_1(valX)\n",
    "\n",
    "        trainY = np.expand_dims(trainY, axis=1)\n",
    "        valY = np.expand_dims(valY, axis=1)\n",
    "\n",
    "        n_splits = math.ceil(m/self.batch_size)\n",
    "\n",
    "        for epoch in np.arange(self.n_epoch):\n",
    "            ixs = np.arange(m)\n",
    "            np.random.shuffle(ixs)\n",
    "            for batch_num, batch_ixs in enumerate(np.array_split(ixs, n_splits)):\n",
    "                self.theta = self.gradient_descent(trainX[batch_ixs], trainY[batch_ixs], self.theta)\n",
    "\n",
    "            training_error = self.cost(trainX, trainY, self.theta)\n",
    "            val_error = self.cost(valX, valY, self.theta)\n",
    "            print(f\"Training epoch#{epoch}: Training error: {training_error}, Validation error: {val_error}\")\n",
    "                  \n",
    "    def predict(self, X, y=None):\n",
    "        X = self.add_1(X)\n",
    "        y_hat = X @ self.theta\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d237f6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78caa85b-0b2d-412a-acbf-607ce0f4add4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model = MLRModel(lr = 0.001, batch_size = 128, n_epoch = 5000)\n",
    "\n",
    "my_model.fit(trainX = columnAdder.fit_transform(train), trainY = train['log_sale_price'].to_numpy(), valX = columnAdder.transform(val), valY = val['log_sale_price'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a0685-fd0f-4f51-b053-b2d53f7ea81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.predict(columnAdder.transform(val)).flatten() # Lets predict the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359b93a-eb14-46c4-8b38-d516954d0bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(val['log_sale_price'], my_model.predict(columnAdder.transform(val)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833f8fb-a5be-4f8d-8e1e-91dff32114da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(columnAdder.fit_transform(train),  train['log_sale_price'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed0ef2-23f8-4fbd-9c13-48ee5e974d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.coef_, lr_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bf7f1-76f7-4f2f-a649-d6a5c7a28fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e462e2-6657-4531-9691-66ee07baff7f",
   "metadata": {},
   "source": [
    "Your my_model parameters should be similar to the sklearn LinearRegression model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e2449-71d2-45ca-8b6c-79ccbf1740ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q18": {
     "name": "q18",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ((1.5 < my_model.theta[0] < 2)[0].item() and (-0.05 < my_model.theta[1] < 0)[0].item()) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.sum(train['Sale Price'] < 500).item() == 0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.array(np.log(train['Sale Price']))[0].item() == np.array(train['log_sale_price'])[0].item()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.shape(bedrooms)[1] == 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
